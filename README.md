# Boulder County Property Tax Assessor (BCPTA)

Boulder County Tax Assessor machine learning algorithmic evaluation

## Tax-paying Resident Investigation

In a world increasingly influenced by machine learned systems, constituents have a right to transparency behind the algorithms that impact them and their families.

Just as policy amendments are voted on democratically in the public arena, so too should AI / ML policies be added to the ballot.

Hope to spur a public discussion around how to formulate a set of governance around how AI / ML systems can be used to affect the public.


ğŸš€ Best ML Task Type: Regression

Since we aim to estimate residential property valuations, this is a supervised learning regression problem where:
	â€¢	Input (Features): Property attributes (size, location, age, quality, etc.).
	â€¢	Target (Output): Sale Price or Time Adjusted Sale Price.



ğŸ” Key Considerations for an Explainable Model

1ï¸âƒ£ Model Choice: Prioritizing Interpretability

Given that the county needs transparency in AI/ML estimates, we should use a model that is:
âœ… Explainable (clear decision process)
âœ… Trustworthy (consistent, interpretable)
âœ… Performs well without being overly complex

Best Models for Explainability:
	1.	Linear Regression (Baseline)
	â€¢	Very easy to explain (coefficients show feature impact).
	â€¢	Good for understanding global trends in property valuation.
	â€¢	ğŸ“Œ Limitation: Doesnâ€™t capture non-linear interactions well.
	2.	Decision Tree Regressor
	â€¢	Easy to visualize & explain decisions step-by-step.
	â€¢	ğŸ“Œ Limitation: Can be unstable if deep (prone to overfitting).
	3.	Random Forest Regressor
	â€¢	More robust & accurate than a single Decision Tree.
	â€¢	Feature Importance ranking explains which factors drive prices.
	â€¢	ğŸ“Œ Limitation: Less interpretable than a single tree, but SHAP values help.
	4.	XGBoost / LightGBM (With SHAP Explainability)
	â€¢	Boosted trees = high accuracy, but interpretable via SHAP values.
	â€¢	ğŸ“Œ Limitation: More complex to explain directly.

2ï¸âƒ£ SHAP & Feature Importance for Transparency

To show constituents how the model makes decisions:
âœ… Use Feature Importance to show which factors drive home prices.
âœ… Use SHAP Values to provide local explanations for each prediction.